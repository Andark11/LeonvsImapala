"""
Le√≥n vs Impala - Sistema de Aprendizaje por Refuerzo
Punto de entrada principal del programa
"""

import sys
import os
import json

# Agregar el directorio actual al path de Python
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ui.entrenamiento_ui import EntrenamientoUI
from storage.carga import cargar_conocimiento


def menu_principal():
    """Men√∫ principal del programa"""
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë                    LE√ìN VS IMPALA                              ‚ïë
    ‚ïë           Sistema de Aprendizaje por Refuerzo                  ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    while True:
        print("\n" + "=" * 70)
        print("MEN√ö PRINCIPAL")
        print("=" * 70)
        print("1. Sistema de Entrenamiento")
        print("2. Simulaci√≥n Visual (Grid 19√ó19)")
        print("3. Acerca del Proyecto")
        print("4. Salir")
        
        opcion = input("\nSelecciona una opci√≥n: ").strip()
        
        if opcion == '1':
            modo_entrenamiento()
        
        elif opcion == '2':
            modo_visualizacion_terminal_grid()
        
        elif opcion == '3':
            mostrar_acerca_de()
        
        elif opcion == '4':
            print("\n¬°Gracias por usar Le√≥n vs Impala!")
            print("Desarrollado como proyecto final de Sistemas Inteligentes\n")
            break
        
        else:
            print("\n‚ùå Opci√≥n inv√°lida")


def modo_entrenamiento():
    """Modo de entrenamiento autom√°tico"""
    ui = EntrenamientoUI()
    ui.menu_principal()


def modo_visualizacion_terminal_grid():
    """Modo de visualizaci√≥n con grid 19√ó19 en terminal (ASCII)"""
    from ui.interfaz_terminal_grid import InterfazTerminalGrid
    from learning.q_learning import QLearning
    from learning.recompensas import SistemaRecompensas
    from knowledge.base_conocimientos import BaseConocimientos
    
    print("\n" + "=" * 70)
    print("MODO VISUALIZACI√ìN - GRID 19√ó19 EN TERMINAL")
    print("="*70)
    print("\nEsta interfaz muestra el grid en la terminal usando ASCII:")
    print("  ‚Ä¢ Grid 19√ó19 completo en caracteres")
    print("  ‚Ä¢ Colores ANSI para mejor visualizaci√≥n")
    print("  ‚Ä¢ Sin dependencias de matplotlib")
    print("  ‚Ä¢ Visualizaci√≥n en tiempo real")
    
    # Detectar soporte de emojis
    usar_emojis = True
    try:
        print("\nü¶Åü¶å ¬øPuedes ver estos emojis correctamente?")
        respuesta = input("(s/n, Enter=s): ").strip().lower()
        if respuesta == 'n':
            usar_emojis = False
            print("‚úì Se usar√°n caracteres ASCII simples (L para le√≥n, I para impala)")
    except:
        usar_emojis = False
    
    print("\n¬øQu√© modo deseas usar?")
    print("  1. Manual (t√∫ decides las acciones del le√≥n)")
    print("  2. Agente entrenado (Q-Learning decide autom√°ticamente)")
    
    modo = input("\nElige opci√≥n (1-2, Enter=1): ").strip() or "1"
    usar_agente = (modo == '2')
    
    # Crear interfaz
    base_conocimientos = BaseConocimientos()
    agente_q = None
    
    if usar_agente:
        print("\nüß† Cargando agente entrenado...")
        try:
            from storage.carga import cargar_conocimiento
            import os
            
            # Buscar archivos de conocimiento disponibles
            ruta_datos = "modelos"
            archivos = []
            if os.path.exists(ruta_datos):
                archivos = sorted([f for f in os.listdir(ruta_datos) if f.endswith("_conocimiento.json")])
            
            if archivos:
                print("\nüìÇ Bases de conocimiento disponibles:")
                for i, archivo in enumerate(archivos, 1):
                    # Obtener tama√±o del archivo
                    ruta = os.path.join(ruta_datos, archivo)
                    tama√±o_kb = os.path.getsize(ruta) / 1024
                    print(f"   {i}. {archivo} ({tama√±o_kb:.1f} KB)")
                
                # Preguntar cu√°l usar
                seleccion = input(f"\n¬øCu√°l usar? (1-{len(archivos)}, Enter={len(archivos)}): ").strip()
                if seleccion == "":
                    indice = len(archivos) - 1  # √öltimo (m√°s reciente)
                else:
                    try:
                        indice = int(seleccion) - 1
                        indice = max(0, min(len(archivos) - 1, indice))
                    except:
                        indice = len(archivos) - 1
                
                archivo_seleccionado = archivos[indice]
                ruta_completa = os.path.join(ruta_datos, archivo_seleccionado)
                print(f"\nüì• Cargando: {archivo_seleccionado}")
                
                # Cargar tambi√©n el archivo de configuraci√≥n para verificar el RADIO
                archivo_config = archivo_seleccionado.replace("_conocimiento.json", "_config.json")
                ruta_config = os.path.join(ruta_datos, archivo_config)
                radio_entrenamiento = None
                if os.path.exists(ruta_config):
                    try:
                        with open(ruta_config, 'r') as f:
                            config_data = json.load(f)
                            if 'abrevadero' in config_data:
                                radio_entrenamiento = config_data['abrevadero'].get('RADIO')
                    except:
                        pass
                
                base_conocimientos = cargar_conocimiento(ruta_completa)
                if base_conocimientos:
                    print("‚úì Base de conocimientos cargada")
                    
                    # Verificar compatibilidad de RADIO
                    from environment import Abrevadero
                    radio_actual = Abrevadero.RADIO
                    
                    if radio_entrenamiento:
                        print(f"   RADIO de entrenamiento: {radio_entrenamiento}")
                        print(f"   RADIO actual: {radio_actual}")
                        
                        if abs(radio_entrenamiento - radio_actual) > 0.1:
                            print("\n‚ö†Ô∏è  ADVERTENCIA: El RADIO cambi√≥")
                            print(f"   Este conocimiento fue entrenado con RADIO={radio_entrenamiento}")
                            print(f"   El RADIO actual es {radio_actual}")
                            print("   El agente puede tener peor rendimiento")
                            print("   Se recomienda re-entrenar con el nuevo RADIO")
                        else:
                            print("‚úì El RADIO coincide con el del entrenamiento")
                    else:
                        print(f"\n‚ö†Ô∏è  No se pudo determinar el RADIO de entrenamiento")
                        print(f"   (Probablemente entrenado con versi√≥n antigua)")
                        print(f"   RADIO actual: {radio_actual}")
                else:
                    print("‚ö†Ô∏è  Error al cargar el archivo")
            else:
                print("‚ö†Ô∏è  No se encontr√≥ conocimiento previo en 'datos/'")
                print("   Ejecuta primero la opci√≥n 1 (Entrenamiento)")
        except Exception as e:
            print(f"‚ö†Ô∏è  Error al cargar: {e}")
            import traceback
            traceback.print_exc()
        
        sistema_recompensas = SistemaRecompensas()
        agente_q = QLearning(base_conocimientos, sistema_recompensas)
    
    interfaz = InterfazTerminalGrid(base_conocimientos, agente_q, usar_emojis)
    
    # Pedir posici√≥n inicial
    import random
    try:
        entrada = input("\nü¶Å Posici√≥n inicial del le√≥n (1-8, Enter=aleatoria): ").strip()
        if entrada:
            posicion = int(entrada)
            posicion = max(1, min(8, posicion))
        else:
            posicion = random.randint(1, 8)
            print(f"   ‚Üí Posici√≥n aleatoria seleccionada: {posicion}")
    except:
        posicion = random.randint(1, 8)
        print(f"   ‚Üí Posici√≥n aleatoria seleccionada: {posicion}")
    
    # Delay para modo autom√°tico
    delay = 1.0
    if usar_agente:
        try:
            delay = float(input("‚è±Ô∏è  Delay entre turnos (segundos, Enter=1.0): ").strip() or "1.0")
        except:
            delay = 1.0
    
    # Visualizar
    try:
        interfaz.visualizar_caceria_interactiva(
            posicion_inicial=posicion,
            usar_agente_entrenado=usar_agente,
            delay=delay
        )
    except KeyboardInterrupt:
        print("\n\nüëã Visualizaci√≥n interrumpida por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error durante la visualizaci√≥n: {e}")
        import traceback
        traceback.print_exc()


def modo_visualizacion_grid():
    """Modo de visualizaci√≥n con grid 19√ó19 interactivo (matplotlib)"""
    try:
        from ui.interfaz_visual_grid import InterfazVisualGrid
        from learning.q_learning import QLearning
        from learning.recompensas import SistemaRecompensas
        from knowledge.base_conocimientos import BaseConocimientos
    except ImportError as e:
        print(f"\n‚ùå Error al importar m√≥dulos de visualizaci√≥n: {e}")
        print("Aseg√∫rate de que matplotlib est√© instalado: pip install matplotlib")
        return
    
    print("\n" + "=" * 70)
    print("MODO VISUALIZACI√ìN - GRID 19√ó19")
    print("=" * 70)
    print("\nEsta interfaz muestra el mapa en un grid 19√ó19 con:")
    print("  ‚Ä¢ Posiciones del le√≥n y el impala")
    print("  ‚Ä¢ Cono de visi√≥n del impala")
    print("  ‚Ä¢ Trayectoria completa del le√≥n")
    print("  ‚Ä¢ Panel de informaci√≥n en tiempo real")
    
    print("\n¬øQu√© modo deseas usar?")
    print("  1. Manual (t√∫ decides las acciones del le√≥n)")
    print("  2. Agente entrenado (Q-Learning decide autom√°ticamente)")
    
    modo = input("\nElige opci√≥n (1-2, Enter=1): ").strip() or "1"
    usar_agente = (modo == '2')
    
    # Crear interfaz
    base_conocimientos = BaseConocimientos()
    agente_q = None
    
    if usar_agente:
        print("\nüß† Cargando agente entrenado...")
        try:
            from storage.carga import cargar_conocimiento
            import os
            
            # Buscar archivos de conocimiento disponibles
            ruta_datos = "modelos"
            archivos = []
            if os.path.exists(ruta_datos):
                archivos = sorted([f for f in os.listdir(ruta_datos) if f.endswith("_conocimiento.json")])
            
            if archivos:
                print("\nüìÇ Bases de conocimiento disponibles:")
                for i, archivo in enumerate(archivos, 1):
                    # Obtener tama√±o del archivo
                    ruta = os.path.join(ruta_datos, archivo)
                    tama√±o_kb = os.path.getsize(ruta) / 1024
                    print(f"   {i}. {archivo} ({tama√±o_kb:.1f} KB)")
                
                # Preguntar cu√°l usar
                seleccion = input(f"\n¬øCu√°l usar? (1-{len(archivos)}, Enter={len(archivos)}): ").strip()
                if seleccion == "":
                    indice = len(archivos) - 1  # √öltimo (m√°s reciente)
                else:
                    try:
                        indice = int(seleccion) - 1
                        indice = max(0, min(len(archivos) - 1, indice))
                    except:
                        indice = len(archivos) - 1
                
                archivo_seleccionado = archivos[indice]
                ruta_completa = os.path.join(ruta_datos, archivo_seleccionado)
                print(f"\nüì• Cargando: {archivo_seleccionado}")
                
                # Cargar tambi√©n el archivo de configuraci√≥n para verificar el RADIO
                archivo_config = archivo_seleccionado.replace("_conocimiento.json", "_config.json")
                ruta_config = os.path.join(ruta_datos, archivo_config)
                radio_entrenamiento = None
                if os.path.exists(ruta_config):
                    try:
                        with open(ruta_config, 'r') as f:
                            config_data = json.load(f)
                            if 'abrevadero' in config_data:
                                radio_entrenamiento = config_data['abrevadero'].get('RADIO')
                    except:
                        pass
                
                base_conocimientos = cargar_conocimiento(ruta_completa)
                if base_conocimientos:
                    print("‚úì Base de conocimientos cargada")
                    
                    # Verificar compatibilidad de RADIO
                    from environment import Abrevadero
                    radio_actual = Abrevadero.RADIO
                    
                    if radio_entrenamiento:
                        print(f"   RADIO de entrenamiento: {radio_entrenamiento}")
                        print(f"   RADIO actual: {radio_actual}")
                        
                        if abs(radio_entrenamiento - radio_actual) > 0.1:
                            print("\n‚ö†Ô∏è  ADVERTENCIA: El RADIO cambi√≥")
                            print(f"   Este conocimiento fue entrenado con RADIO={radio_entrenamiento}")
                            print(f"   El RADIO actual es {radio_actual}")
                            print("   El agente puede tener peor rendimiento")
                            print("   Se recomienda re-entrenar con el nuevo RADIO")
                        else:
                            print("‚úì El RADIO coincide con el del entrenamiento")
                    else:
                        print(f"\n‚ö†Ô∏è  No se pudo determinar el RADIO de entrenamiento")
                        print(f"   (Probablemente entrenado con versi√≥n antigua)")
                        print(f"   RADIO actual: {radio_actual}")
                    
                    sistema_recompensas = SistemaRecompensas()
                    agente_q = QLearning(base_conocimientos, sistema_recompensas)
                else:
                    print("‚ö†Ô∏è  Error al cargar el archivo")
                    print("Se usar√° un agente sin entrenamiento")
                    sistema_recompensas = SistemaRecompensas()
                    agente_q = QLearning(base_conocimientos, sistema_recompensas)
            else:
                print("‚ö†Ô∏è  No se encontr√≥ conocimiento previo en 'datos/'")
                print("   Ejecuta primero la opci√≥n 1 (Entrenamiento)")
                print("Se usar√° un agente sin entrenamiento")
                sistema_recompensas = SistemaRecompensas()
                agente_q = QLearning(base_conocimientos, sistema_recompensas)
        except Exception as e:
            print(f"‚ö†Ô∏è  Error al cargar: {e}")
            print("Se usar√° un agente sin entrenamiento")
            import traceback
            traceback.print_exc()
    
    interfaz = InterfazVisualGrid(base_conocimientos, agente_q)
    
    # Pedir posici√≥n inicial
    import random
    try:
        entrada = input("\nü¶Å Posici√≥n inicial del le√≥n (1-8, Enter=aleatoria): ").strip()
        if entrada:
            posicion = int(entrada)
            posicion = max(1, min(8, posicion))
        else:
            posicion = random.randint(1, 8)
            print(f"   ‚Üí Posici√≥n aleatoria seleccionada: {posicion}")
    except:
        posicion = random.randint(1, 8)
        print(f"   ‚Üí Posici√≥n aleatoria seleccionada: {posicion}")
    
    # Visualizar
    try:
        interfaz.visualizar_caceria_interactiva(
            posicion_inicial=posicion,
            usar_agente_entrenado=usar_agente
        )
    except KeyboardInterrupt:
        print("\n\nüëã Visualizaci√≥n interrumpida por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error durante la visualizaci√≥n: {e}")
        import traceback
        traceback.print_exc()


def modo_visualizacion():
    """Modo de visualizaci√≥n paso a paso sin entrenamiento"""
    print("\n" + "=" * 70)
    print("MODO VISUALIZACI√ìN - SIN ENTRENAMIENTO (TEXTO)")
    print("=" * 70)
    print("El le√≥n tomar√° decisiones aleatorias")
    
    ui = PasoAPasoUI()
    
    import random
    try:
        entrada = input("\nPosici√≥n inicial del le√≥n (1-8, Enter=aleatoria): ").strip()
        if entrada:
            posicion = int(entrada)
            if not 1 <= posicion <= 8:
                posicion = 1
        else:
            posicion = random.randint(1, 8)
            print(f"   ‚Üí Posici√≥n aleatoria seleccionada: {posicion}")
    except:
        posicion = random.randint(1, 8)
        print(f"   ‚Üí Posici√≥n aleatoria seleccionada: {posicion}")
    
    print("\nTipo de visualizaci√≥n:")
    print("1. Paso a paso (manual)")
    print("2. Autom√°tica (con delay)")
    
    tipo = input("Selecciona (1/2, Enter=1): ").strip() or "1"
    
    try:
        if tipo == '2':
            delay = float(input("Delay entre turnos en segundos (Enter=1.0): ").strip() or "1.0")
            ui.visualizar_con_delay(posicion, delay)
        else:
            ui.visualizar_caceria(posicion)
    except KeyboardInterrupt:
        print("\n\nVisualizaci√≥n interrumpida")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")


def modo_visualizacion_entrenado():
    """Modo de visualizaci√≥n con le√≥n entrenado"""
    print("\n" + "=" * 70)
    print("MODO VISUALIZACI√ìN - CON LE√ìN ENTRENADO")
    print("=" * 70)
    
    from storage.guardado import listar_guardados
    
    guardados = listar_guardados("modelos")
    
    if not guardados:
        print("\n‚ùå No hay entrenamientos guardados")
        print("Primero debes entrenar al le√≥n usando la opci√≥n 1 del men√∫ principal")
        return
    
    print("\nEntrenamientos disponibles:")
    for i, guardado in enumerate(guardados, 1):
        print(f"{i}. {guardado['archivo']} - Tasa de √©xito: {guardado['tasa_exito']}%")
    
    try:
        seleccion = int(input("\nSelecciona un entrenamiento (n√∫mero): ")) - 1
        if not 0 <= seleccion < len(guardados):
            print("‚ùå Selecci√≥n inv√°lida")
            return
        
        guardado = guardados[seleccion]
        
        # Cargar conocimiento
        print(f"\nCargando {guardado['archivo']}...")
        bc = cargar_conocimiento(guardado['ruta'])
        
        if not bc:
            print("‚ùå Error al cargar el conocimiento")
            return
        
        print(f"‚úì Conocimiento cargado exitosamente")
        print(f"  Estados √∫nicos: {guardado['estados']}")
        print(f"  Tasa de √©xito: {guardado['tasa_exito']}%")
        
        # Crear UI con conocimiento
        ui = PasoAPasoUI(base_conocimientos=bc)
        
        import random
        entrada = input("\nPosici√≥n inicial del le√≥n (1-8, Enter=aleatoria): ").strip()
        if entrada:
            posicion = int(entrada)
            if not 1 <= posicion <= 8:
                posicion = 1
        else:
            posicion = random.randint(1, 8)
            print(f"   ‚Üí Posici√≥n aleatoria seleccionada: {posicion}")
        
        print("\nTipo de visualizaci√≥n:")
        print("1. Paso a paso (manual)")
        print("2. Autom√°tica (con delay)")
        
        tipo = input("Selecciona (1/2, Enter=1): ").strip() or "1"
        
        if tipo == '2':
            delay = float(input("Delay entre turnos en segundos (Enter=1.0): ").strip() or "1.0")
            ui.visualizar_con_delay(posicion, delay)
        else:
            ui.visualizar_caceria(posicion)
    
    except KeyboardInterrupt:
        print("\n\nVisualizaci√≥n interrumpida")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")


def mostrar_acerca_de():
    """Muestra informaci√≥n del proyecto"""
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë                  ACERCA DE LE√ìN VS IMPALA                      ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    
    DESCRIPCI√ìN:
    Sistema de aprendizaje autom√°tico donde un le√≥n joven aprende a 
    cazar un impala en un abrevadero mediante aprendizaje por refuerzo.
    
    CARACTER√çSTICAS:
    ‚Ä¢ Aprendizaje basado en Q-Learning
    ‚Ä¢ Entrenamiento autom√°tico de miles de episodios
    ‚Ä¢ Generalizaci√≥n de conocimiento
    ‚Ä¢ Visualizaci√≥n paso a paso
    ‚Ä¢ Persistencia de conocimiento aprendido
    
    COMPONENTES:
    ‚Ä¢ Entorno: Abrevadero con 8 posiciones
    ‚Ä¢ Agentes: Le√≥n (aprende) e Impala (presa)
    ‚Ä¢ Aprendizaje: Algoritmo Q-Learning
    ‚Ä¢ Base de conocimientos: Estados ‚Üí Acciones ‚Üí Resultados
    
    REGLAS DEL JUEGO:
    1. El impala act√∫a primero (ver, beber, huir)
    2. El le√≥n reacciona (avanzar, esconderse, atacar)
    3. El impala huye si detecta al le√≥n o si est√° muy cerca
    4. El le√≥n gana si alcanza al impala
    5. El le√≥n pierde si el impala escapa
    
    VELOCIDADES:
    ‚Ä¢ Le√≥n avanzando: 1 cuadro/turno
    ‚Ä¢ Le√≥n atacando: 2 cuadros/turno
    ‚Ä¢ Impala huyendo: 1, 2, 3, 4... cuadros/turno (acelera)
    
    DESARROLLO:
    Arquitectura modular en Python con separaci√≥n de responsabilidades:
    - environment.py: Mapa y geometr√≠a
    - agents/: Comportamiento de le√≥n e impala
    - simulation/: L√≥gica de cacer√≠a
    - knowledge/: Base de conocimientos y generalizaci√≥n
    - learning/: Q-Learning y entrenamiento
    - ui/: Interfaces de usuario
    - storage/: Persistencia
    
    TECNOLOG√çAS:
    ‚Ä¢ Python 3.8+
    ‚Ä¢ Q-Learning (Reinforcement Learning)
    ‚Ä¢ Arquitectura modular y orientada a objetos
    
    PROYECTO FINAL - SISTEMAS INTELIGENTES
    """)
    
    input("\nPresiona Enter para continuar...")


def verificar_directorios():
    """Verifica y crea directorios necesarios"""
    directorios = ['modelos']
    for directorio in directorios:
        if not os.path.exists(directorio):
            os.makedirs(directorio)
            print(f"‚úì Creado directorio: {directorio}")


if __name__ == "__main__":
    try:
        # Verificar directorios necesarios
        verificar_directorios()
        
        # Iniciar men√∫ principal
        menu_principal()
    
    except KeyboardInterrupt:
        print("\n\nüëã Programa interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error fatal: {e}")
        import traceback
        traceback.print_exc()
