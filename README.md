# ğŸ¦ LeÃ³n vs Impala - Q-Learning

Sistema de aprendizaje por refuerzo donde un leÃ³n aprende a cazar un impala mediante **Q-Learning**. El leÃ³n aprende Ãºnicamente por experiencia, sin estrategias preprogramadas.

[![Python3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

## ğŸ¯ CaracterÃ­sticas

- âœ… **Q-Learning** con exploraciÃ³n epsilon-greedy
- âœ… **VisualizaciÃ³n ASCII** en terminal (Grid 19Ã—19)
- âœ… **Coordenadas polares** para movimiento natural
- âœ… **11 constantes de recompensa** ajustables
- âœ… **Persistencia JSON** de modelos entrenados
- âœ… **9 tests unitarios** completos
- âœ… **Sin dependencias externas** (solo stdlib Python)

## ğŸš€ InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/Andark11/LeonvsImapala.git
cd LeonvsImapala

# Verificar Python 3.8+
python --version

# Ejecutar
python main.py
```

## ğŸ“– Uso

**Entrenar modelo:**
```bash
python main.py
# OpciÃ³n 1: Entrenar nuevo modelo
# Episodios recomendados: 100,000
```

**Visualizar cacerÃ­a:**
```bash
python main.py
# OpciÃ³n 2: SimulaciÃ³n visual paso a paso
```

**Ejecutar tests:**
```bash
python tests/test_basico.py
```

## ğŸ§  Q-Learning

### EcuaciÃ³n de Bellman
```
Q(s,a) â† Q(s,a) + Î±[r + Î³Â·max Q(s',a') - Q(s,a)]
```

**ParÃ¡metros:**
- Î± = 0.05 (tasa de aprendizaje)
- Î³ = 0.9 (factor de descuento)
- Îµ = 1.0 â†’ 0.1 (exploraciÃ³n decreciente)

## ğŸ® Acciones

### LeÃ³n (4 acciones)
- **AVANZAR**: 1 cuadro/turno (movimiento sigiloso)
- **ESCONDERSE**: Invisible para el impala
- **ATACAR**: 2 cuadros/turno (sprint final)
- **SITUARSE**: Cambiar posiciÃ³n inicial

### Impala (5 acciones)
- **VER_IZQUIERDA/DERECHA/FRENTE**: Cono visiÃ³n 120Â°
- **BEBER_AGUA**: Vulnerable (no ve al leÃ³n)
- **HUIR**: AceleraciÃ³n 1â†’2â†’3... cuadros/turno

## âš–ï¸ Sistema de Recompensas

| Evento | Valor |
|--------|-------|
| Ã‰xito cacerÃ­a | +100.0 |
| Fracaso cacerÃ­a | -50.0 |
| Acercamiento | +1.0/cuadro |
| Alejamiento | -2.0/cuadro |
| DetecciÃ³n temprana | -5.0 a -10.0 |
| Tiempo excesivo | -0.1/turno |
| Buen uso esconderse | +2.0 |
| Mal uso esconderse | -1.0 |
| Ataque cercano (â‰¤2) | +5.0 |
| Ataque lejano (>3) | -3.0 |

## ğŸŒ Coordenadas Polares

```
        N (0Â°)
         |
    8    1    2
     \   |   /
  7 -- AB -- 3
     /   |   \
    6    5    4
         |
       S (180Â°)
```

- **AB**: Abrevadero (centro)
- **RADIO**: 9.5 unidades
- **ConversiÃ³n**: x = rÂ·sin(Î¸), y = rÂ·cos(Î¸)

## ğŸ“ Estructura

```
LeonvsImapala/
â”œâ”€â”€ main.py              # Punto de entrada
â”œâ”€â”€ environment.py       # Sistema de coordenadas
â”œâ”€â”€ agents/             # LeÃ³n e impala
â”œâ”€â”€ simulation/         # Motor de cacerÃ­a
â”œâ”€â”€ learning/           # Q-Learning y recompensas
â”œâ”€â”€ knowledge/          # Base de conocimientos
â”œâ”€â”€ storage/            # Persistencia JSON
â”œâ”€â”€ ui/                 # Interfaces
â”œâ”€â”€ tests/              # Tests unitarios
â”œâ”€â”€ modelos/            # Modelos entrenados
â””â”€â”€ docs/               # DocumentaciÃ³n LaTeX (67 pÃ¡gs)
```

## ğŸ“Š Resultados

**Modelo EM4 (100,000 episodios):**
- Tasa de Ã©xito: **10.45%**
- Tiempo: ~15 minutos
- Experiencias: 145,135 Ãºnicas

**ProgresiÃ³n:**
- 1K episodios â†’ 3-4% Ã©xito
- 10K episodios â†’ 6-8% Ã©xito
- 100K episodios â†’ 10-12% Ã©xito

## ğŸ§ª Tests

9 tests unitarios (100% pasando):
- Coordenadas polares y distancias
- Acciones de leÃ³n e impala
- Q-Learning y epsilon-greedy
- Sistema de recompensas
- CacerÃ­a completa end-to-end

## ğŸ”§ ConfiguraciÃ³n

**Ajustar parÃ¡metros Q-Learning** (`learning/q_learning.py`):
```python
alpha = 0.05      # Tasa de aprendizaje
gamma = 0.9       # Factor de descuento
epsilon = 1.0     # ExploraciÃ³n inicial
```

**Ajustar recompensas** (`learning/recompensas.py`):
```python
EXITO_CACERIA = 100.0
FRACASO_CACERIA = -50.0
# ... mÃ¡s constantes
```

## ï¿½ï¿½ DocumentaciÃ³n

DocumentaciÃ³n acadÃ©mica completa en LaTeX (67 pÃ¡ginas):
```bash
cd docs
xdg-open main.pdf
```

**Contenido:** 6 capÃ­tulos + 3 apÃ©ndices con cÃ³digo, instalaciÃ³n y anÃ¡lisis de resultados.

## ğŸ‘¨â€ğŸ’» Autores

**Proyecto Final - Sistemas Inteligentes**

**Integrantes:**
- Alvarado MartÃ­nez Miguel Eduardo
- GarcÃ­a Retana Alba Sughey
- Soria Cabrera AndrÃ©s
- Sosa PÃ©rez Dariana Montserrat

**Profesor:** Rosas HernÃ¡ndez Javier  
**Grupo:** 1754  
**InstituciÃ³n:** FES AcatlÃ¡n, UNAM

## ğŸ“„ Licencia

Todos los derechos reservados.

---

**VersiÃ³n:** 1.0.0 | **Fecha:** Diciembre 2025 | **Repositorio:** [github.com/Andark11/LeonvsImapala](https://github.com/Andark11/LeonvsImapala)
